---
title: Forecasting model for Consumer Goods Appliances by Optimal Reconciliation for
  Hierarcical and Grouped Times Series through Trace minimization
author: "PGP BABI-K19 - Group 4"
date: "15 January 2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r cars}
library(readr)
library(tidyverse)
library(fabletools)
library(fpp3)
```

REading the data and converting it into a time series tibble format

```{r pressure, echo=FALSE}
setwd("C:\\Users\\surya\\Desktop\\GL BABI\\Capstone GL")

data_t10 <- readr::read_csv("data_t10.csv" )

data_t10 <- data_t10 %>%
  mutate(month = yearmonth(date))%>%
  as_tsibble(key = c(product, city), index = month)

class(data_t10)

```

We can see from above output that data is converted into tbl_ts class.We need to check whether there are any gaps in the time series segments.

```{r}
has_gaps(data_t10, .full = T)
```

No gaps are detected in the series time segments. We will derive the time series features from the data set like strength of trend and seasonality. Also we will apply STL decomposition for checking the components of time series

```{r}

#Time Series Components

data_t10 %>%
  STL(sales ~ trend(window=21) + season(window = 13), robust = TRUE) %>%
  autoplot()

#Time Series features

data_t10 %>%
  features(sales, feature_set(tags = "stl"))

#Measuring STL features and Trend & Seasonality strength

data_t10 %>% 
  features(sales, feat_stl) 

#Plotting the features

data_t10 %>% 
  features(sales, feat_stl) %>% 
  ggplot(aes(x = trend_strength, y = seasonal_strength_year, col = product))+
  geom_point() + facet_wrap(vars(city))

#Measuring the average trend strength of the product 

data_t10 %>%
  features(sales, feat_stl) %>%
  group_by(product) %>% 
  summarise(avg_trend_str = mean(trend_strength))
  
#Measuring the average seasonal strength of the product 

data_t10 %>%
  features(sales, feat_stl) %>%
  group_by(product) %>% 
  summarise(avg_season_str = mean(seasonal_strength_year))

#Measuring the average trend strength of the city 
data_t10 %>%
  features(sales, feat_stl) %>%
  group_by(city) %>% 
  summarise(avg_trend_str = mean(trend_strength))
```

Now we need to divide the data into test and train components and use aggts() function in order to aggregate the data into base time series. We will use 3 years of data as train data and 1 year of data for validation.

```{r}
#Training and Testing for t5 data

t10_train <- data_t10 %>%
  group_by(product, city) %>%
  slice(1:36)

t10_test <- data_t10 %>%
  group_by(product, city) %>%
  slice(37:48)

#Creating aggregates for Forecasting

data_t10_agg <- data_t10 %>%
  aggregate_key( product * city , sales = sum(sales))


train_agg <- t10_train %>%
  aggregate_key( product * city , sales = sum(sales))

test_agg <- t10_test %>%
  aggregate_key( product * city , sales = sum(sales))
```

ETS Modelling:

We will use both simple ETS approach and Optimal reconciliation approach for ETS in modelling.

```{r}
fc <- t10_train %>%
  aggregate_key(product*city, sales= sum(sales)) %>%
  model(ets = ETS(sales)) %>%
  reconcile(ets_adjusted = min_trace(ets)) %>%
  forecast(h=12)

fc %>%
  filter(is_aggregated(product) & is_aggregated(city)) %>%
  autoplot(train_agg, level=95)

```

Forcasting Results for City- Kolkata & Forecasting results for Product Mixers.
```{r}
#By City - Kolkata

fc %>%
  filter(is_aggregated(product) & city=="Kolkata") %>%
  autoplot(train_agg, level=95)

#By Product - Mixers

fc %>%
  filter(is_aggregated(city) & product=="Mixers") %>%
  autoplot(train_agg, level=95)
```

Forecast Evaluation - ETS Modelling

```{r}
fc %>%
  accuracy(test_agg) 

fc %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(RMSE = mean(RMSE)) %>%
  arrange(RMSE)

fc %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAPE = mean(MAPE)) %>%
  arrange(MAPE)

fc %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MASE = mean(MASE)) %>%
  arrange(MASE)

fc %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAE = mean(MAE)) %>%
  arrange(MAE)

fc %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(ME = mean(ME)) %>%
  arrange(ME)



```

ARIMA Modelling:

```{r}
#ARIMA Modelling

fc1 <- t10_train %>%
  aggregate_key(product*city, sales= sum(sales)) %>%
  model(arima = ARIMA(sales)) %>%
  reconcile(arima_adjusted = min_trace(arima)) %>%
  forecast(h=12)

fc1

fc1 %>%
  filter(is_aggregated(product) & is_aggregated(city)) %>%
  autoplot(train_agg, level=95)
```

Plotting the ARIMA forecasting by product and city

```{r}
#By City

fc1 %>%
  filter(is_aggregated(product) & city=="Kolkata") %>%
  autoplot(train_agg, level=95)

#By Product

fc1 %>%
  filter(is_aggregated(city) & product=="Mixers") %>%
  autoplot(train_agg, level=95)

```

Forecast Evaluation:


```{r}
fc1 %>%
  accuracy(test_agg) 

fc1 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(RMSE = mean(RMSE)) %>%
  arrange(RMSE)

fc1 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAPE = mean(MAPE)) %>%
  arrange(MAPE)

fc1 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MASE = mean(MASE)) %>%
  arrange(MASE)

fc1 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAE = mean(MAE)) %>%
  arrange(MAE)

fc1 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(ME = mean(ME)) %>%
  arrange(ME)
```

SNAIVE Modelling:

```{r}

fc2 <- t10_train %>%
  aggregate_key(product*city, sales= sum(sales)) %>%
  model(snaive = SNAIVE(sales)) %>%
  reconcile(snaive_adjusted = min_trace(snaive)) %>%
  forecast(h=12)

fc2 %>%
  filter(is_aggregated(product) & is_aggregated(city)) %>%
  autoplot(train_agg, level=95)


```

Plotting the SNAIVE Forecasting results by City Wise and Product Wise

```{r}
#By City

fc2 %>%
  filter(is_aggregated(product) & city=="Kolkata") %>%
  autoplot(train_agg, level=95)

#By Product

fc2 %>%
  filter(is_aggregated(city) & product=="Mixers") %>%
  autoplot(train_agg, level=95)
```

Forecast Evaluation for SNAIVE:

```{r}
fc2 %>%
  accuracy(test_agg) 

fc2 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(RMSE = mean(RMSE)) %>%
  arrange(RMSE)

fc2 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAPE = mean(MAPE)) %>%
  arrange(MAPE)

fc2 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MASE = mean(MASE)) %>%
  arrange(MASE)

fc2 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAE = mean(MAE)) %>%
  arrange(MAE)

fc2 %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(ME = mean(ME)) %>%
  arrange(ME)
```

We are getting MAPE as infinity because some of the observations in the time series are zero. Also, MASE is displayed as NaN due the requirement of minimum of 13 observations in validation data for calculation. We will now check the Ensemble approach. We take a simple average of all the forecasting results and create an ensemble model.

Ensemble Approach:

```{r}
fc_comb <- train_agg %>%
  model(
    ets = ETS(sales),
    arima = ARIMA(sales),
    snaive = SNAIVE(sales)
  ) %>%
  mutate(
    comb = (ets+arima+snaive)/3
  ) %>%
  reconcile(
    ets_adj = min_trace(ets),
    arima_adj = min_trace(arima),
    snaive_adj = min_trace(snaive),
    comb_adj = min_trace(comb)
  ) %>%
  forecast(h = 12)

fc_comb %>%
  filter(is_aggregated(product) & is_aggregated(city)) %>%
  autoplot(train_agg, level=95)
```

Forecast Plotting of Ensemble Model by City and Product

```{r}
#By City

fc_comb %>%
  filter(is_aggregated(product) & city=="Kolkata") %>%
  autoplot(train_agg, level=95)

#By Product

fc_comb %>%
  filter(is_aggregated(city) & product=="Mixers") %>%
  autoplot(train_agg, level=95)

```

Forecast Evaluation - Ensemble Model

```{r}
fc_comb %>%
  accuracy(test_agg) 

fc_comb %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(RMSE = mean(RMSE)) %>%
  arrange(RMSE)

fc_comb %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAPE = mean(MAPE)) %>%
  arrange(MAPE)

fc_comb %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MASE = mean(MASE)) %>%
  arrange(MASE)

fc_comb %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(MAE = mean(MAE)) %>%
  arrange(MAE)

fc_comb %>%
  accuracy(test_agg) %>%
  group_by(.model) %>%
  summarise(ME = mean(ME)) %>%
  arrange(ME)
```

In order to better understand the forecasting results and accuracy measurements we will test our models on three individual series foor 4 Products and 4 Cities Combinations. They are Mixers - Kolkata, Coolers - Mumbai, Dry Iron - Bangalore, and Water Heaters - Hyderabad 

```{r}
# Kolkate - Mixers

kol_mix <- fc_comb %>%
  filter(product == "Mixers" & city == "Kolkata")

fc_comb %>%
  filter(product == "Mixers" & city == "Kolkata") %>%
  autoplot(train_agg, ylab = "Mixer Sales Forecasting for Kolkata", level = 95)
  

fc_comb %>%
  filter(product == "Mixers" & city == "Kolkata") %>% 
  accuracy(test_agg) %>%
  group_by(.model)

#Mumbai - Coolers

mum_col <- fc_comb %>%
  filter(product == "coolers" & city == "Mumabi")
  
fc_comb %>%
  filter(product == "coolers" & city == "Mumbai") %>%
  autoplot(train_agg, level = 95)
  
fc_comb %>%
  filter(product == "coolers" & city == "Mumbai") %>% 
  accuracy(test_agg) %>%
  group_by(.model)

#Bangalore - Dry Iron

ban_di <- fc_comb %>%
  filter(product == "Dry Iron" & city == "Bangalore")

fc_comb %>%
  filter(product == "Dry Iron" & city == "Bangalore") %>%
  autoplot(train_agg, level = 95)

fc_comb %>%
  filter(product == "Dry Iron" & city == "Bangalore") %>% 
  accuracy(test_agg) %>%
  group_by(.model)

##Hyderabad - Water Heaters

fc_comb %>%
  filter(product == "Water Heaters" & city == "Hyderabad") %>% 
  accuracy(test_agg) %>%
  group_by(.model)
```


























